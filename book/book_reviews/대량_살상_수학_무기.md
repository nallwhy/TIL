# 대량 살상 수학 무기

인간은 재미있다.



어느 한 명을 평가해야하는데 만약 잘못 평가했을 때 그 사람의 인생이 망가질 수 있다면 큰 부담을 가지고 평가하게 되겠지만,

자신과 동료들이 함께 만든 알고리즘이 수십, 수백만 명을 평가하면서 그 중에 수백, 수천 명의 인생을 끝장 낼 때는 별 생각이 없다.



기존에 사용하던 방법들이라고해서 이 책에서 비난하는 알고리즘보다 더 잘 작동했으리라고 생각할 수 없다.

예전으로 돌아가자는 얘기를 하는 것은 아니다.

알고리즘을 이용해서 99.9%를 제대로 판단하고 0.1%를 잘못 판단한다면, 잘못 판단한 케이스에 대해 구제해줄 수 있다면 문제는 해결될 것이다.

하지만 문제는 그것이 불가능한 경우다.

기술적으로는 요즘 많이 쓰이는 인공신경망 알고리즘을 사람이 해석할 수 없어서 문제가 무엇인지 알 수 없다는 것부터,

인간적으로는 많은 사람들은 자신들이 피해를 봤는지 알아차리기도 힘들고 알아차렸다고 하더라도 그것을 해결하기 힘들다는 것까지 해결하기 힘든 문제가 문제 해결의 길을 겹겹이 막고있다.

차라리 기술적 문제는 나중에 해결될지 몰라도 인간적 문제는 해결이 결단코 불가능하다.


앞으로 이런 알고리즘은 분명히 더 많은 곳에 쓰인다.

경제 논리로는 이 정도 효율을 안쓸리가 없다.

그래서 책 중반부터 생각했지만, 이 책의 마무리에서도 말하듯 법을 통해 해결하는 수밖에 없다.

문제가 생길 수 있는 데이터를 알고리즘에 사용하지 못하도록하고, 결과에 대한 피드백을 강제해야한다.



좀 더 시선을 뒤로 빼서, 알고리즘에 우리들의 선택을 맡기는 것은 마냥 괜찮은 일일까?

알고리즘이 알려주는 내 적성 결과로 내 미래의 방향을 설정하고

알고리즘이 나와 가장 잘맞는 이성이라고 추천해주는 사람들과만 데이트하고

알고리즘이 내 취향이라며 제공하는 뉴스만 계속 보면

괜찮은건가?

조금 더 미래에는 이러한 질문들이 상상 속 고민이 아닌 현실의 고민으로 다가올 것이다.

지금은 브레이크를 잡을 생각이 아무도 없기 때문이다.

알고리즘은 점점 더 정확해질 것이고 세상은 점점 더 알고리즘을 신뢰할 것이다.

점점 더 내 데이터가 알고리즘을 만드는 것이 아니라 알고리즘이 나를 만들게 될 것이다.



우리는 어디까지 이것을 받아들일지 적정선을 결정해야한다.

---

WMD 의 피드백 루프.

인공지능이 나에게 맞는 사람을 매칭해주는데 그래서 나는 그런 사람 밖에 만나보지 못한다면? 많은 사람들이 첫 연애에서 아무 것도 몰라 원래 그런가보다 하고서 피해를 받는? 경우 들이 많이 있다.

데이터과학자가 거래 대상이 되는 사람들을 생각하지 않는다.
한 명에 대해 평가를 내리라고 하면 아마 신경을 많이 쓸 것이다. 하지만 그 대상이 수십만 수천만이 되었을 때는 더 이상 한 명의 의미가 크지 않다.

"저희는 99.9% 의 정확도를 가지고 있습니다." 수천만 명 중 수만명은? 어쩔 수 없는 일인가. 기존의 모델에서는 100% 였는가? 아닐 것이다. 그럼 이러한 예외 케이스에대한 구제만 잘 되면 되는것 아닌가.
ex) 수능.
http://smartaedi.tistory.com/136
내가 원하는 뉴스만 보는 것이 옳은 방향인가?

모형들에는 대개 개발자의 목표와 이념이 반영된다
그래서 누가, 무엇의 위해 만들었는지 알아야한다.


언론의 대학평가. 세계화 지수 따위를 넣어서 대학이 망가졌다.
아무것도 모르는 애들이 평가기준을 만드니까 대학이 거기에 목매.

다양성 없는 절대 기준은 피해자를 양산
이력서. 분석하는 프로그램을 만드는 곳에서 컨설팅도 한다.

http://www.ttimes.co.kr/view.html?no=2018020817057769106

현실을 반영해 수정하기보다는 원하는 현실을 창조한다.

인간이 평가하는 시스템은 옳은가? 그렇지는 않다.
하지만 규모가 차이가 난다고 한다.

분명히 쓸 것이다.
앞으로 이런 일이 있을 때 우리는 어떻게 해야하는가

효율과 정확성
기업인 이상 효율을 신경쓸 수밖에 없다.
그럼 어떻게 해야하지.
그저 시장논리에 맡기면 해결이 될 수 없다.
법으로 해결해야한다.
앞으로 세상에는 이렇게 사회적 합의로 처리되어야 할 상황이 더 많아질것.

좋은 의도라고 좋은 결과가 나오는 것은 아니다
피드백의 필요성

문제는 머신러닝은 절대 내부가 투명해질수 없어.
